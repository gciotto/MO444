%%% PREAMBLE - Do not touch %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{bm}
\usepackage{model}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
\input{pics/abaco}

\cvprfinalcopy % *** Uncomment this line for the final submission
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}
\ifcvprfinal\pagestyle{empty}\fi


%%% Report beginning %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%% Title and authors %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title {Predizendo o modelo da câmera de um foto a partir de técnicas de aprendizado de maáquina}
\author{Gustavo Ciotto Pinton, RA117136\thanks{Is with the Institute of Computing, University of Campinas (Unicamp). \textbf{Contact}: \tt\small{gustavociotto@gmail.com}}}

%%% Abstract %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\maketitle
\begin{abstract}
São propostos neste documento dois métodos de classificação, baseados em aprendizado de máquina, capazes de determinar, a partir de uma foto, o modelo da câmera que a gerou. No total, 10 modelos de câmeras distintas, mas de mesmos fabricantes, são utilizados neste problema. O primeiro método, baseado na técnica de regressão logística, consiste em separar as 10 classes em grupos binários de maneira a testar sempre um dos modelos contra os demais, enquanto que o segundo, baseado em redes neurais, busca diretamente a classe de determinada imagem, sem quaisquer divisão binária dos grupos. Além disso, neste artigo, estão descritos os atributos recuperados das imagens e os parâmetros configurados em cada um dos métodos, bem como a sua influência no resultado final.
\end{abstract}

%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introdução}
\label{intro}

A técnica de regressão logistíca, ao contrário do método de regressão linear explorado na última atividade que tem como objetivo modelar os dados de dados em um equação linear, busca classificar os dados de entrada em dois grupos discretos, comumente denominados \(0\) e \(1\). 

consiste em uma técnica simples cujo objetivo é relacionar um conjunto de dados de entrada com os de saída através do uso de uma equação linear \(Y = \theta_0 + \theta_1X_1 + \theta_2X_2 + \ldots + \theta_NX_N\), em que \(Y\), \(X_i\) e \(\theta_i\) representam, respectivamente, a saída gerada pelo modelo a partir de um conjunto de atributos e os coeficientes da equação. A equação anterior é utilizada apenas para uma amostra singular, porém, como visto em aula, o principal aspecto que garante a qualidade de resultados obtidos por métodos de aprendizado de máquina é o grande volume de dados. Tendo isso em vista, um conjunto de \(M\) amostras de entrada descritas por \(N\) atributos é representado pela matriz \(\bm{x}_{N+1\times M}\). Da mesma maneira, os coeficientes da equação são representados pelo vetor \(\bm{\theta}\) de \(N+1\) elementos e a saída, pelo vetor \(\bm{y}\) de \(M\) valores, de forma a obter a equação vetorial \ref{lr}, logo abaixo.

\begin{equation}
\label {lr}
\bm{y} = \bm{\theta}^T\bm{x}
\end{equation}

A determinação das componentes de \(\bm{\theta}\) é realizada a partir da minimização da função de custo \(J(\bm{\theta}, \bm{x})\), descrita pela equação \ref{cost}, em que \(\bm{x}_ i\) corresponde à i-ésima amostra e \(t_ i\) ao \textit{target} que deseja-se atingir.

\begin{equation}
\label {cost}
J(\bm{\theta}, \bm{x}) = \frac{1}{2M} \displaystyle\sum_{i=1}^{M} \left(\bm{\theta}^T\bm{x}^{(i)} - \bm{t}^{(i)}\right)^2
\end{equation}

Os dados utilizados para a minimização \(\bm{x}\) e \(\bm{t}^{(i)}\) pertencem a um conjunto chamado \textbf{conjunto de treinamento}, enquanto que a validação dos parâmetros obtidos ocorre em um conjunto que recebe este mesmo nome. Um regra geral é separar 80\% dos dados disponíveis para treinamento e o restante, 20\%, para testes e validação.

A função de custo \(J(\bm{\theta}, \bm{x})\) possui a importante propriedade de ser \textbf{convexa} \cite{Bishop:2006:PRM:1162264}. Isso garante que ela não possui mínimos locais, exceto pelo global. Deste modo, dois métodos de minimização podem ser utilizados. O primeiro, chamado de \textbf{equação normal}, permite obter o \(\bm{\theta}\) ótimo a partir de uma única expressão, representada em \ref{normal}. Observa-se rapidamente que o ponto negativo desta abordagem é o cálculo da matriz inversa, cuja complexidade assimptótica de computação é \(\Theta(n^3)\), conforme visto em aula. Para a matrix \(\bm{x}^T\bm{x}\) de dimensão \(N+1 \times N+1\), portanto, o número de atributos \(N\) pode representar um impedimento para o uso desta técnica.

\begin{equation}
\label {normal}
\bm{\theta} = \left(\bm{x}^T\bm{x}\right)^{-1} \bm{x}^T \bm{t}
\end{equation}

O segundo método, chamado de \textbf{gradient descent}, é iterativo e não requer o cálculo de nenhuma matriz inversa. Derivando-se parcialmente a equação \ref{cost} em relação a \(\bm{\theta}_j\), obtém-se o coeficiente linear e portanto a direção que devemos tomar para nos aproximar do mínimo global. Repetindo o raciocínio para todos os parâmetros \(\bm{\theta}_j\), obtém-se à operação \ref{gd} que deve ser aplicada a cada um deles a cada iteração. Ressalta-se que \(\bm{x}_1 = 1\) para todo \(i\).

\begin{equation}
\label {gd}
\bm{\theta}_j = \bm{\theta}_j - \alpha\frac{\partial J}{\partial \bm{\theta}_j } = \bm{\theta}_j - \frac{\alpha}{M} \displaystyle\sum_{i=1}^{M} \left(\bm{\theta}^T\bm{x}^{(i)} - \bm{t}^{(i)}\right)\bm{x}_j^{(i)}
\end{equation}

A equação \ref{gd} introduz o parâmetro \(\alpha\), chamado de \textit{learning rate}. Tal parâmetro controla a velocidade de convergência ao mínimo global, isto é, quanto maior o seu valor mais rapidamente ele é atingido. Por outro lado, valores muito grandes produzirão um efeito denominado \textit {overshooting}, isto é, a solução encontrada sempre ficará \textit{balançando} ao redor do mínimo sem nunca atingí-lo. Nas próximas seções, o autor explica a estratégia para a definição desta grandeza para o problema deste relatório.

Tendo visto toda teoria por trás da regressão linear, podemos aplicá-la a dados reais. Neste relatório, usamos dados reais \cite{database} da rede social \textit{Mashable}, que visam relacionar uma série de atributos de uma determinada publicação com o número de \textit{shares} que ela recebeu. Em outras palavras, busca-se encontrar uma relação linear entre o número de \textit{shares} recebidos com os atributos de uma publicação. No total, 31715 dados foram usados para treinamento dos modelos e 7929 para teste e validação.

%%% Add section %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Atividades}

As próximas subseções visam explicar as escolhas dos diversos parâmetros adotados pelo autor.

\subsection{Ajuste do learning rate}
\label{sec:ajuste}
Conforme mencionado na seção \ref{intro}, o parâmetro \textit{learning rate} controla a velocidade de convergência ao mínimo global da função de custo. Tendo em vista as questões levantadas nesta mesma seção, adota-se um valor \(\alpha\) inicial igual a 0.5, modificando-o em apenas duas situações:

\begin{itemize}
	\item Quando o erro da iteração \(k\) é superior aquele da iteração \(k -1\). Neste caso, conclui-se que a solução encontrada foi pior e, portanto, devemos diminuir a velocidade de convergência.
	\item A variação do erro entre as iterações \(k\) e \(k -1\), isto é, \(\frac{R_{k - 1} - R_k}{R_k}\), foi inferior a uma porcentagem \(\Delta = 0.5\%\). Neste caso, deseja-se eliminar os efeitos de \textit{overshooting} e aproximar o melhor possível do mínimo global. Denota-se de \(R_k\), dado pela fórmula \ref {rms}, o \textit{root-mean-square error} obtido na iteração \(k\):
	\begin {equation}
	\label{rms}
	R_k = \sqrt{\frac {\sum_{i=1}^{M} \left(\bm{\theta}_k^T\bm{x}^{(i)} - \bm{t}^{(i)}\right)^2}{M}}
	\end{equation}
\end{itemize}

Nestes dois casos, o valor de \(\alpha\) é diminuído pela metade.

\subsection {Ajuste das variáveis discretas}

A descrição dos atributos de cada uma das entradas revelou a presença de algumas variáveis discretas. Dois grupos foram identificados: um com variáveis do tipo \textit{a publicação ocorreu na segunda-feira?}, \textit{a publicação ocorreu na terça-feira?} e assim por diante, e outro com atributos semelhantes a \textit{o canal é de entretenimento?}. Antes de utilizá-las ou não nos modelos propostos a seguir, é preciso verificar se tais variáveis são \textbf {ortogonais} entre si, isto é, se a distância entre elas consideradas duas a duas é sempre a mesma. Levando-se em consideração que as variáveis de ambos os grupos nunca podem ser setadas simultaneamente (uma publicação não pode ocorrer na segunda e na terça e ela não pode pertencer a dois canais ao mesmo tempo, por exemplo), observa-se a propriedade de \textbf {ortogonalidade} e, portanto, podemos utilizá-las sem quaisquer modificações.

\subsection {Normalização dos dados de entrada e de saída}

A normalização dos dados antes do treinamento previne que os valores \(\bm{\theta}_j\) sejam extremamente pequenos ou grandes de forma a
causar instabilidades ou interferir na velocidade de convergência do modelo. Dentre as muitas maneiras de normalização que podem ser aplicadas, escolhemos para esta atividade aquela da equação \ref{norm}. Neste caso, são calculados a média \(\mu_j\) e o desvio padrão \(\sigma_j\) de cada \textit{feature} \(\bm {x'}_j\) sobre todas as amostras de treinamento e depois é aplicada a expressão \ref{norm}.

\begin {equation}
\label {norm}
\bm {x'}_j = \frac {\bm{x}_j - \mu_j}{\sigma_j}
\end{equation}

Vale lembrar que os valores \(\mu_j\) e \(\sigma_j\) devem ser amarzenados para serem utilizados posteriormente no conjunto de teste e em qualquer outra entrada a ser aplicada no modelo.

\subsection{Regularização}

\label{sec:reg}

A regularização é uma técnica que permite limitar os efeitos negativos de \textit{overfitting} sem a eliminação de nenhum atributo do modelo a partir da penalização dos parâmetros \(\bm{\theta}_j\). Neste caso, a equação \ref{cost} torna-se:

\begin{equation}
\label {cost-reg}
J(\bm{\theta}, \bm{x}) = \frac{1}{2M} \left[\displaystyle\sum_{i=1}^{M} \left(\bm{\theta}^T\bm{x}^{(i)} - \bm{t}^{(i)}\right)^2 + \lambda \displaystyle\sum_{j=2}^{N + 1} \bm{\theta}_j^2 \right]
\end{equation}

Observa-se que se \(\lambda\) é muito grande, então o processo de minimização produzirá \(\bm{\theta}_j\) pequenos, resultando em um modelo polarizado que não seria bem-sucedido em se adequar corretamente aos dados. Em oposição, \(\lambda\) pequenos não conseguiriam combater os efeitos de \textit{overfitting} e a variação criada pelos dados de testes seria grande.

A equação \ref{norm}, por sua vez, transforma-se na expressão \ref{normal-reg}, sendo \(\bm{I}_{N \times N}\) a matriz identidade:

\begin{equation}
\label {normal-reg}
\bm{\theta} = \left(\bm{x}^T\bm{x} + \lambda
\begin{bmatrix}
    0       & 0 \\
    0       & \bm{I}_{N \times N} \\
\end{bmatrix}
\right)^{-1} \bm{x}^T \bm{t}
\end{equation}

Destaca-se que \(\bm{\theta}_1\) não é penalizado.

%%% Add section %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Soluções propostas}

Essa seção é dedicada à discussão das soluções propostas. Foram realizados testes com modelos simples, regularizados e contendo variáveis de segunda e terceira ordens.

\subsection {Modelo linear simples}

Neste modelo, utiliza-se o método de regressão linear sem regularização e sem quaisquer termos de segunda ou terceira ordens. Para a técnica de \textit{gradient descent}, itera-se a fórmula \ref{gd} 100 vezes no total. A figura \ref{fig:lr-gd} representa os erros quadrados médios conforme equação \ref{rms} obtidos no treinamento e no teste a cada iteração. Observa-se que ambos os erros se estabilizam em torno de, respectivamente, 10700 e 14700, e que não há a presença dos efeitos negativos de \textit {overfitting}.

\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{img/lr-gd.png}
    \caption{RMS obtidos no treinamento e teste a cada iteração.}
    \label{fig:lr-gd}
\end{figure}

A figura \ref{fig:lr-norm}, por sua vez, representa os resultados encontrados a partir do uso da expressão \ref{norm}. Dois gráficos são mostrados: no primeiro, compara-se os erros obtidos no treinamento e teste para diversos tamanhos de conjuntos de entrada indo de 10000 até 31715, enquanto que no segundo, compara-se os vetores \(\bm{\theta}\) obtidos pelos dois métodos descritos nessa seção. Conforme esperado, o RMS encontrado para o método normal, em torno de 10580, foi inferior aquele encontrado por \textit{gradient descent}. O erro de teste, por sua vez, também ficou em torno de 14570. Observa-se também que algumas diferenças consideráveis entre os vetores \(\bm{\theta}\) sobretudo para os conjuntos de dados com tamanhos intermediários.

\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{img/lr-norm.png}
    \caption{RMS obtidos no treinamento e teste para diversos números de amostras.}
    \label{fig:lr-norm}
\end{figure}

\subsection{Modelo linear simples regularizado}

Apesar de não ter sido observado efeitos de \textit{overfitting} nos resultados anteriores, propomos o uso da regularização, conforme explicado na subseção \ref{sec:reg}. Foram testados dois valores de \(\lambda\), um igual a 1.0 e o outro, vinte vezes maior, 20.0. A figura \ref{fig:reg-comparison} compara os resultados encontrados para a técnica de \textit{gradient descent} entre os modelos regularizados e aquele da subseção anterior. Verifica-se que, para estes casos, a regularização não modificou substantivamente o erro encontrado, tanto para o conjunto de treinamento quanto o de teste. Isso indica que os valores sugeridos de \(\lambda\) são muito pequenos quando comparados a cada um dos fatores \(\bm{\theta}_j^2\) individualmente.  Estes mesmos modelos também foram submetidos às equações normais, porém, assim como no \textit{gradient descent}, nenhuma grande alteração foi observada.

\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{img/lr-comparation.png}
    \caption{RMS obtidos nos modelos regularizados.}
    \label{fig:reg-comparison}
\end{figure}

\subsection{Redução de atributos do modelo}

Uma outra tentativa realizada para minimizar o erro foi reduzir o número de atributos utilizados para o modelo. A seleção dos atributos foi feita de acordo com a correlação de cada um deles em relação à saída, uma vez que, como o modelo ainda é linear, espera-se que variáveis mais correlatas sigam o mesmo padrão que aquele observado na saída. A figura \ref {fig:correlation} representa apenas as 10 variáveis mais correlatas e que foram utilizadas para o novo modelo proposto. Vale dizer que a correlação mais alta, correspondente ao atributo 25 (\textit{Avg. keyword (avg. shares)}), ainda é um valor bem baixo, isto é, 0.125, indicando que nenhuma vaiável influencia fortemente o número de compartilhamentos de uma publicação. A figura \ref{fig:comparison-selection} compara os resultados encontrados para o modelo linear simples e para o modelo proposto nesta subseção. Observa-se um ligeiro aumento do erro de treinamento para o modelo reduzido a partir da iteração 10, indicando uma leve presença de \textit {overfitting}. Além disso, verifica-se que ambos os erros de treinamento e teste do modelo reduzido convergem mais rapidamente do que aqueles do modelos simples aos valores onde permanecem praticamente constantes. Por fim, ressalta-se que as equações normais também foram utilizadas, porém seus resultados não são representados neste relatório por efeitos de simplificação.

\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{img/lr-selection.png}
    \caption{Correlação dos atributos de entrada com a saída.}
    \label{fig:correlation}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{img/lr-comparation-selection.png}
    \caption{Comparação entre modelo linear simples e aquele com as 10 variáveis mais correlatas com a saída.}
    \label{fig:comparison-selection}
\end{figure}

\subsection{Modelo linear com atributos de segunda ordem}

Outra técnica que pode ser empregada para reduzir os erros de treinamento e teste é a adição de novos atributos baseados nos já existentes ao modelo simples. Nessa etapa, portanto, adiciona-se ao modelo linear simples todas as suas variáveis ao quadrado, de forma a obter a nova relação \(Y_2 = Y + \theta_{N+1}X_1^2 + \theta_{N+2}X_2^2 + \ldots + \theta_{2N}X_N^2\). Espera-se com esse novo modelo uma melhor adequação aos dados de treinamento e aos de teste simultaneamente, isto é, sem a observação de \textit{overfitting}.  Vale lembrar que as equações \ref{normal} e \ref{gd} não sofrem quaisquer alterações, dado o fato que a equação de custo \ref{cost} continua linear em \(\bm{\theta}\). A figura \ref{fig:gd-second} possui o resultado da técnica de \textit{gradient descent} para este modelo. Observa-se que na iteração 17, o valor de \(\alpha\) é modificado, conforme descrito na seção \ref{sec:ajuste}, uma vez que o erro produzido foi superior àquele encontrado na iteração precedente. Os erros RMS de treinamento e de teste ao fim de 100 iterações encontrados foram, respectivamente, 11830 e 15570, superiores àqueles verificados para o modelo linear simples. O uso da equação \ref{normal}, por sua vez, resultou em erros em torno de 10540 e 14580, muito parecidos àqueles obtidos pela mesma técnica aplicado ao modelo linear simples.

\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{img/lr-second-gd.png}
    \caption{RMS obtidos no treinamento e teste do modelo com atributos de segunda ordem a cada iteração.}
    \label{fig:gd-second}
\end{figure}

\subsection{Modelo linear com atributos de terceira ordem}

O último modelo testado neste relatório utilizou atributos de segunda e terceira ordens, obtendo a expressão \(Y_3 = Y_2 + \theta_{2N+1}X_1^3 + \theta_{2N+2}X_2^3 + \ldots + \theta_{3N}X_N^3\). A figura \ref{fig:gd-third} possui a evolução dos erros encontrados no decorrer das 100 iterações. Assim como ocorrido na figura \ref{fig:gd-second}, o valor do parâmetro \(\alpha\) - \textit{learning rate} - teve que ser diminuído, já que o erro de treinamento da iteração 3 foi superior àquele da iteração 2. Os menores erros RMS encontrados para treinamento e teste foram, respectivamente, 12743 e 16208, superiores àqueles obtidos no modelo linear simples. Por fim, o uso das equações normais resultou em erros iguais a 10458 e 15084. O primeiro foi ligeiramente inferior àquele do modelo simples, enquanto que o segundo, superior. Esse fato ilustra bem uma das dificuldades encontradas quando aumenta-se a complexidade do modelo, o \textit{overfitting}. Neste caso, diminui-se o erro do conjunto de treinamento, porém aumenta-se o do conjunto de teste, indicando que o modelo se adequou de maneira exagerada aos dados de treinamento. Conforme já discutido, uma das possíveis soluções a este problema é a regularização.

\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{img/lr-third-gd.png}
    \caption{RMS obtidos no treinamento e teste do modelo com atributos de segunda e terceira ordens a cada iteração.}
    \label{fig:gd-third}
\end{figure}

%%% Add section %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}

Cinco modelos lineares foram propostos para a predição do número de compartilhamentos de uma publicação da rede social Mashable. Em praticamente todos eles, os erros RMS de treinamento e teste ficaram em torno de 10500 e 14500, respectivamente, indicando que o modelo linear não é capaz de modelar com precisão o comportamento dos usuários desta rede social.

%%% References %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
{\small
\bibliographystyle{unsrt}
\bibliography{refs}
}

\end{document}
